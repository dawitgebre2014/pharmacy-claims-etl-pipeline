# Pharmacy Claims ETL Pipeline (Simulated Databricks Project)

This project demonstrates an end-to-end ETL pipeline for processing pharmacy claims data using SQL and Python. Inspired by real-world PBM operations, it simulates how raw claims data can be transformed into refined, analytics-ready outputs.

## 💡 Use Case

Automating pharmacy claims data processing to:
- Filter and clean claims (e.g., only paid claims)
- Generate derived fields such as `claim_month` and `high_cost_flag`
- Summarize claim counts and costs by month and drug
- Streamline reporting and reduce manual effort

## 📁 Files

| File | Description |
|------|-------------|
| `claims_raw.csv` | Synthetic source data (raw claims) |
| `pipeline_etl.py` | Python script simulating Databricks workflow |
| `pipeline_steps.sql` | SQL version of the transformation logic |
| `claims_summary.csv` | Output summary table (generated by script) |

## 🧪 How to Run

### Python ETL:
```bash
python pipeline_etl.py
```
This will generate a `claims_summary.csv` file with monthly and drug-level summaries.

### SQL Alternative:
Use `pipeline_steps.sql` in a SQL environment (Databricks, Snowflake, or SQL Server) with a table named `claims_raw`.

## 📊 Sample Metrics in Final Output
- Total claims per drug per month
- Total & average cost
- Count of high-cost claims (> $100)

## 🔧 Tools Used
- Python (Pandas)
- SQL (CTEs & aggregations)
- Jupyter/Databricks-style modular pipeline approach

## 🔍 Why This Project?

This simulates a real workflow I’ve built in Databricks to automate weekly PBM reporting. The original version reduced manual data prep by 70% and enabled faster quality checks and delivery of cost insights.

---

*Created by Dawit Gebre*
